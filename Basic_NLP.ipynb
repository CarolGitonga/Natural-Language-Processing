{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOlSyZFTUYvwq4qy/tAWYQS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarolGitonga/Natural-Language-Processing/blob/main/Basic_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI6fuG4vwdRO",
        "outputId": "4a180bf9-e6fd-44ae-ed3a-251723e90376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dependencies\n",
        "import numpy as np\n",
        "import re\n",
        "import requests\n",
        "import nltk\n",
        "nltk.download('gutenberg', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "from nltk.corpus import gutenberg, stopwords, wordnet\n",
        "from nltk import FreqDist, word_tokenize, pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
        "from nltk.util import trigrams\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from collections import Counter\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "import string\n",
        "import pathlib\n",
        "import math\n",
        "import contractions\n",
        "from itertools import islice"
      ],
      "metadata": {
        "id": "UIsCV0LNwufa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def request_gutenberg(url):\n",
        "\n",
        "  # Make a request to the url\n",
        "  response = requests.get(url)\n",
        "\n",
        "  # check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "    book = response.text\n",
        "\n",
        "  else:\n",
        "    print(f\"Failed to retrieve the text version. Status code: {response.status_code}\")\n",
        "\n",
        "  # remove unwanted new line and tab characters from the text, replacing with whitespace\n",
        "  unwanted_chars = [\"\\n\", \"\\r\", \"\\d\", \"\\t\"]\n",
        "  for char in unwanted_chars:\n",
        "      book = book.replace(char, \" \")\n",
        "\n",
        "  return book\n",
        "\n",
        "# URLs of the books to be used in this lab\n",
        "g_gatsby_url = \"https://www.gutenberg.org/cache/epub/64317/pg64317.txt\"\n",
        "huckleberry_finn_url = \"https://www.gutenberg.org/cache/epub/76/pg76.txt\"\n",
        "sherlock_holmes_url = \"https://www.gutenberg.org/files/1661/1661-0.txt\"\n",
        "\n",
        "# Make requests for each book\n",
        "g_gatsby = request_gutenberg(g_gatsby_url)[1494:277912] # Remove introduction and footnotes\n",
        "h_berry = request_gutenberg(huckleberry_finn_url)[9528:-18862]\n",
        "s_holmes = request_gutenberg(sherlock_holmes_url)[1508:-18859]\n",
        "\n",
        "books = {\n",
        "    \"The Great Gatsby\": g_gatsby,\n",
        "    \"Adventures of Huckleberry Finn\": h_berry,\n",
        "    \"The Adventures of Sherlock Holmes\": s_holmes\n",
        "    }\n",
        "\n",
        "# Preview\n",
        "for key, val in books.items():\n",
        "  print(f\"{key}:\")\n",
        "  print(val[:500])\n",
        "  print(\"=\"*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMrCwGQSxCIJ",
        "outputId": "0e3ebd1d-302b-41aa-cfb5-9c95f9156ff8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Great Gatsby:\n",
            "I    In my younger and more vulnerable years my father gave me some advice  that I’ve been turning over in my mind ever since.    “Whenever you feel like criticizing anyone,” he told me, “just  remember that all the people in this world haven’t had the advantages  that you’ve had.”    He didn’t say any more, but we’ve always been unusually communicative  in a reserved way, and I understood that he meant a great deal more  than that. In consequence, I’m inclined to reserve all judgements, a  habi\n",
            "====================================================================================================\n",
            "Adventures of Huckleberry Finn:\n",
            "CHAPTER I.      You don’t know about me without you have read a book by the name of The  Adventures of Tom Sawyer; but that ain’t no matter. That book was made  by Mr. Mark Twain, and he told the truth, mainly. There was things  which he stretched, but mainly he told the truth. That is nothing. I  never seen anybody but lied one time or another, without it was Aunt  Polly, or the widow, or maybe Mary. Aunt Polly—Tom’s Aunt Polly, she  is—and Mary, and the Widow Douglas is all told about in that \n",
            "====================================================================================================\n",
            "The Adventures of Sherlock Holmes:\n",
            "A SCANDAL IN BOHEMIA      I.    To Sherlock Holmes she is always _the_ woman. I have seldom heard him  mention her under any other name. In his eyes she eclipses and  predominates the whole of her sex. It was not that he felt any emotion  akin to love for Irene Adler. All emotions, and that one particularly,  were abhorrent to his cold, precise but admirably balanced mind. He  was, I take it, the most perfect reasoning and observing machine that  the world has seen, but as a lover he would have \n",
            "====================================================================================================\n"
          ]
        }
      ]
    }
  ]
}